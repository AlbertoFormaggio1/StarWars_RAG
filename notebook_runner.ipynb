{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_EgKO9KBrNs",
        "outputId": "38f4cccd-5e89-4baf-c4b2-90704e4610b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install beautifulsoup4\n",
        "!pip install langchain\n",
        "!pip install langchain-community==0.2.1 langchain-core==0.2.1\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "!pip install accelerate\n",
        "!pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm70bs3m-uh8"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import wiki_scrape as ws\n",
        "import RAG_chain as rc\n",
        "import argparse\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_Bo_hXUKqqH"
      },
      "outputs": [],
      "source": [
        "retrieve_movies = False\n",
        "retrieve_characters = False\n",
        "retrieve_series = False\n",
        "chunk_type = \"Recursive\"\n",
        "chunk_size = 800\n",
        "chunk_overlap = 100\n",
        "model_id = \"Ba2han/Phi-3-Medium-Llamaish\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHxecAnlABYR"
      },
      "outputs": [],
      "source": [
        "def chunk_docs(docs):\n",
        "    headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\"), (\"h3\", \"Header 3\"), (\"h4\", \"Header 4\")]\n",
        "    params = {}\n",
        "\n",
        "    match chunk_type:\n",
        "        case \"Recursive\":\n",
        "            separators = [\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
        "            params[\"separators\"] = separators\n",
        "            params[\"chunk_size\"] = chunk_size\n",
        "            params[\"chunk_overlap\"] = chunk_overlap\n",
        "\n",
        "            chunks = rc.chunk(docs, headers_to_split_on, chunk_type, **params)\n",
        "\n",
        "    print(\"Number of chunks: \", len(chunks))\n",
        "    print(\"Number of documents: \", len(docs))\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXaioaaALSn6"
      },
      "source": [
        "Retrieve movies if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_xvRvDQAMu9"
      },
      "outputs": [],
      "source": [
        "    if retrieve_movies:\n",
        "        ws.export_movies()\n",
        "    if retrieve_characters:\n",
        "        ws.export_characters()\n",
        "    if retrieve_series:\n",
        "        ws.export_series()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0OfqvgILVd0"
      },
      "source": [
        "Read the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHZbP5TtLWSh",
        "outputId": "538991d0-5ddc-4b3e-e507-f9f96c3da812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing Documents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114/114 [00:00<00:00, 8282.96it/s]\n"
          ]
        }
      ],
      "source": [
        "print(\"Importing Documents\")\n",
        "docs = rc.read_docs(\"./web_pages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7pEjlYGLbY7"
      },
      "source": [
        "Chunk documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E_IiIorLbGE",
        "outputId": "50ce79f7-5ce5-4cc9-bd4c-5a3179dd9977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating chunks\n",
            "Number of chunks:  1296\n",
            "Number of documents:  114\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating chunks\")\n",
        "chunks = chunk_docs(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHyZ6EpBLiPh"
      },
      "source": [
        "Create vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dKEQPjXLkIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52b0428-f796-44b2-82d7-a7476a56809b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a vector store\n",
            "Generating retriever\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating a vector store\")\n",
        "embedding_model, vector_index = rc.create_vector_index_and_embedding_model(chunks)\n",
        "print(\"Generating retriever\")\n",
        "retriever = vector_index.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLJTpjj4LoFR"
      },
      "source": [
        "Create the LLM pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "1JjAzvz7Ln81",
        "outputId": "e38c68c7-6715-4258-8a67-9615805b0723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading LLM model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'RAG_chain' has no attribute 'generate_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fffd66a0dbc9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading LLM model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'RAG_chain' has no attribute 'generate_model'"
          ]
        }
      ],
      "source": [
        "print(\"Downloading LLM model\")\n",
        "model, tokenizer = rc.generate_model(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating the langchain pipeline\")\n",
        "llm_pipeline = rc.create_pipeline(model, tokenizer)"
      ],
      "metadata": {
        "id": "PmuW-JlNNn3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzE60wW-Lx3T"
      },
      "source": [
        "Create the chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7t4qlfULxtf"
      },
      "outputs": [],
      "source": [
        "print(\"Creating chain\")\n",
        "chain = rc.create_qa_RAG_chain(llm_pipeline, retriever)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}